{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Feature Extraction with \n",
    "#1) SelectKBest function with algorithm f_regression -> F-value between label/feature for regression tasks.\n",
    "#2) Recursive Feature Elimination\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import f_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from copy import deepcopy\n",
    "from patsy import dmatrices\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pickle\n",
    "import cPickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas version, needs to be 0.18+ 0.19.0\n"
     ]
    }
   ],
   "source": [
    "print \"pandas version, needs to be 0.18+\", pd.__version__\n",
    "#print \"sklearn version, needs to be 0.18+\", sklearn.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#args: rootdir -> root directory, ending -> file ending\n",
    "#return: list of pathes in rootdir \n",
    "def lsdir(rootdir, ending):\n",
    "    pathlist = []\n",
    "    for root,  dirs,  files in os.walk(rootdir,  topdown=False):\n",
    "        for filename in files:\n",
    "            if ending in filename:\n",
    "                pathlist.append(filename)\n",
    "    return pathlist\n",
    "\n",
    "#read in a pickled dataframe for an episode in TAKE\n",
    "#input: speaker, episode number, directorypath\n",
    "#return: unpickled dataframe for episode\n",
    "def open_pkl_ep(speaker,ep,ep_path):\n",
    "    \n",
    "    fname = ep_path+'r'+str(int(speaker))+'_'+str(ep)+'.pkl'\n",
    "    \n",
    "    with open(fname,'rb') as fp:\n",
    "        ep_df = pickle.load(fp)\n",
    "    #ep_df = pd.read_pickle(fname)\n",
    "    ep_df = ep_df[['speaker', 'episode', 'time_in_sec',\\\n",
    "                   'label','label_dur',\\\n",
    "                   'pcm_LOGenergy_sma', 'pcm_RMSenergy_sma',\\\n",
    "                   'pcm_intensity_sma', 'intensity_mean','intensity_slope', \\\n",
    "                   'pcm_loudness_sma', \\\n",
    "                   'phones',\\\n",
    "                   'duration', 'zscore', \\\n",
    "                   'wml',  'wml_trigram',\\\n",
    "                   'rms_minus_four',  'rms_minus_one', \\\n",
    "                   'rms_minus_three',  'rms_minus_two',\\\n",
    "                   'voicingFinalUnclipped_sma',\\\n",
    "                   'voicingFinalUnclipped_slope', 'words' ]]\n",
    "    #if ep==2.0:\n",
    "    #    print ep_df.keys()\n",
    "    return ep_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create the training set\n",
    "#input: speaker, path to directory of pickled episodes\n",
    "#return: dataframe for train\n",
    "def get_train_all(eps_path,return_individual_fold=False, limit_of_final_trps=.75):\n",
    "      \n",
    "    train = pd.DataFrame() if not return_individual_fold else [] #list if folds\n",
    "    pathlist = []\n",
    "    \n",
    "    print 'Get list of paths...'\n",
    "    for sp in range(2,8):\n",
    "        pathlist += lsdir(eps_path+'r'+str(int(sp))+'/', '.pkl')\n",
    "\n",
    "    print 'Load pickled episodes into Dataframe...'\n",
    "    lsp=1\n",
    "    speaker_dict = {}\n",
    "    out=[]\n",
    "    \n",
    "    for path in pathlist:\n",
    "        ep = path.split('_')[1].split('.pkl')[0]\n",
    "        speak = path.split('_')[0][1]\n",
    "        eppath = eps_path+'r'+str(int(speak))+'/'#+path\n",
    "        \n",
    "\n",
    "        try:\n",
    "            train_ep = open_pkl_ep(speak,ep,eppath)\n",
    "        except:\n",
    "            print speak, ep\n",
    "            continue\n",
    "\n",
    "        train_ep = train_ep.drop(train_ep[(train_ep.label == 2)&(train_ep.label_dur>limit_of_final_trps)].index)\n",
    "        train_ep = train_ep.drop(train_ep[(train_ep.time_in_sec < 1.01)].index)\n",
    "        #print len(train_ep)\n",
    "        #break\n",
    "        \n",
    "        if int(speak) != int(lsp):\n",
    "            print \"speaker\", speak\n",
    "            speaker_dict[int(speak)] = pd.DataFrame()\n",
    "            lsp = speak\n",
    "            #print train_ep.keys()\n",
    "        \n",
    "        if return_individual_fold:\n",
    "            speaker_dict[int(speak)] = speaker_dict[int(speak)].append(deepcopy(train_ep))\n",
    "        else:\n",
    "            out_tupel = (int(speak),int(float(ep)))\n",
    "            if out_tupel in out:\n",
    "                print 'out ',speak,ep\n",
    "                continue\n",
    "            else:\n",
    "                train = train.append(deepcopy(train_ep))\n",
    "    print \"training data loaded\"\n",
    "    \n",
    "    if return_individual_fold:\n",
    "        train = [speaker_dict[key] for key in sorted(speaker_dict.keys())]\n",
    "    return train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get list of paths...\n",
      "Load pickled episodes into Dataframe...\n",
      "speaker 2\n",
      "speaker 3\n",
      "speaker 4\n",
      "speaker 5\n",
      "speaker 6\n",
      "6 129\n",
      "6 138\n",
      "6 150\n",
      "speaker 7\n",
      "training data loaded\n"
     ]
    }
   ],
   "source": [
    "eps_path = './../../Data/pickled_episodes_1/'\n",
    "train_all = get_train_all(eps_path,return_individual_fold=False, limit_of_final_trps=.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#some possible feature combinations\n",
    "rmsfeats = 'label ~ time_in_sec +\\\n",
    "pcm_LOGenergy_sma + pcm_loudness_sma +\\\n",
    "pcm_RMSenergy_sma + rms_minus_one + rms_minus_two + rms_minus_three + rms_minus_four'\n",
    "\n",
    "rmsfeats_raw = 'label ~ time_in_sec +\\\n",
    "pcm_RMSenergy_sma + rms_minus_one + rms_minus_two + rms_minus_three + rms_minus_four'\n",
    "\n",
    "durfeats = 'label ~ time_in_sec +\\\n",
    "zscore + duration'\n",
    "\n",
    "intensity = 'label ~ time_in_sec +\\\n",
    "pcm_intensity_sma  + intensity_mean + intensity_slope'\n",
    "\n",
    "rmsintens = 'label ~ time_in_sec +\\\n",
    "pcm_RMSenergy_sma + rms_minus_one + rms_minus_two + rms_minus_three + rms_minus_four+\\\n",
    "pcm_intensity_sma  + intensity_mean + intensity_slope'\n",
    "\n",
    "lm_features = 'label ~ time_in_sec + wml + wml_trigram'\n",
    "\n",
    "rmsfeatslm = rmsfeats + \" + \"+ lm_features[lm_features.find('time_in_sec +')+13:]\n",
    "durfeatslm = durfeats + \" + \"+ lm_features[lm_features.find('time_in_sec +')+13:]\n",
    "intensitylm = intensity + \" + \"+ lm_features[lm_features.find('time_in_sec +')+13:]\n",
    "rmsintenslm = rmsintens + \" + \"+ lm_features[lm_features.find('time_in_sec +')+13:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "########################acoustic + lm features:###################################\n",
    "#the best features are changing with respect to the heldout speaker!\n",
    "\n",
    "acoustic = 'label ~ time_in_sec +\\\n",
    "pcm_RMSenergy_sma + rms_minus_one + rms_minus_two + rms_minus_three + rms_minus_four +\\\n",
    "pcm_LOGenergy_sma + pcm_loudness_sma + pcm_intensity_sma  +\\\n",
    "zscore + duration + intensity_mean + intensity_slope + voicingFinalUnclipped_sma + \\\n",
    "voicingFinalUnclipped_slope'\n",
    "\n",
    "lm_features = 'label ~ time_in_sec + wml + wml_trigram'\n",
    "acousticlm = acoustic + \" + \" + lm_features[lm_features.find('time_in_sec +')+13:]\n",
    "\n",
    "features = acousticlm\n",
    "\n",
    "##################################################################################\n",
    "##################################################################################\n",
    "##################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['time_in_sec', 'pcm_RMSenergy_sma', 'rms_minus_one', 'rms_minus_two', 'rms_minus_three', 'rms_minus_four', 'pcm_LOGenergy_sma', 'pcm_loudness_sma', 'pcm_intensity_sma', 'zscore', 'duration', 'intensity_mean', 'intensity_slope', 'voicingFinalUnclipped_sma', 'voicingFinalUnclipped_slope', 'wml', 'wml_trigram']\n"
     ]
    }
   ],
   "source": [
    "names = [feat.strip() for feat in features.split('~')[1].split('+')]\n",
    "print names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "24181.2743604\tduration\n",
      "17407.3516293\twml\n",
      "6195.8368421\ttime_in_sec\n",
      "1975.45283182\tzscore\n",
      "1861.78644428\twml_trigram\n",
      "1654.67304781\tpcm_LOGenergy_sma\n",
      "1034.57107893\tvoicingFinalUnclipped_sma\n",
      "3\n",
      "35656.2548934\tduration\n",
      "21178.3788933\tpcm_LOGenergy_sma\n",
      "13316.8443968\tpcm_loudness_sma\n",
      "8356.45248668\tzscore\n",
      "6938.69133701\ttime_in_sec\n",
      "6244.50874177\tintensity_mean\n",
      "4804.60936546\twml\n",
      "4\n",
      "35023.6663408\tduration\n",
      "17068.6481341\tpcm_LOGenergy_sma\n",
      "10382.9180605\ttime_in_sec\n",
      "9454.72793341\tpcm_loudness_sma\n",
      "5525.67335702\tzscore\n",
      "4515.13170003\tintensity_mean\n",
      "3310.14603072\trms_minus_two\n",
      "5\n",
      "45064.8041336\tduration\n",
      "15113.1079834\tpcm_LOGenergy_sma\n",
      "9413.79196808\ttime_in_sec\n",
      "8171.16782011\tpcm_loudness_sma\n",
      "5335.71987502\tzscore\n",
      "3996.53030784\tintensity_mean\n",
      "3617.02651878\twml\n",
      "6\n",
      "39240.9185981\tduration\n",
      "9500.41290694\ttime_in_sec\n",
      "8151.80435382\twml\n",
      "5843.40671776\tpcm_LOGenergy_sma\n",
      "3130.97534668\tpcm_loudness_sma\n",
      "1846.37825995\tzscore\n",
      "1437.2505186\tintensity_mean\n",
      "7\n",
      "36435.0740785\tduration\n",
      "18552.3220307\tpcm_LOGenergy_sma\n",
      "11908.8013552\tpcm_loudness_sma\n",
      "7837.21493525\ttime_in_sec\n",
      "6008.04820826\twml\n",
      "5989.12765333\tzscore\n",
      "5764.61298704\tintensity_mean\n"
     ]
    }
   ],
   "source": [
    "'''Apply the SelectKBest function on the data'''\n",
    "for out in range(2,8):\n",
    "    #transform data\n",
    "    print out\n",
    "    train = deepcopy(train_all)\n",
    "    train = train[train['speaker']!=out]\n",
    "    #transform data\n",
    "    y, X = dmatrices(features, train, return_type=\"dataframe\")\n",
    "    y = np.ravel(y)\n",
    "    # feature extraction\n",
    "    number_best_features = 6\n",
    "    test = SelectKBest(score_func=f_regression, k=number_best_features)\n",
    "    fit = test.fit(X, y)\n",
    "    ###################\n",
    "    # summarize scores\n",
    "    np.set_printoptions(precision=3)\n",
    "    name_dict = {str(i+1):names[i] for i in range(len(names))}\n",
    "    name_dict['0'] = 'NAN'\n",
    "    all_results = sorted([(list(fit.scores_)[i],name_dict[str(i)]) for i in range(len(list(fit.scores_)))])\n",
    "    all_results = list(reversed(all_results)) \n",
    "    results = all_results[:number_best_features+1]\n",
    "    print \"\\n\".join([str(tupel[0])+\"\\t\"+tupel[1] for tupel in results])\n",
    "    #ranked_features = fit.transform(X)\n",
    "    # summarize selected features\n",
    "    #print(ranked_features[0:5,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Recursive Feature Elimination (RFE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Features: 3\n",
      "Selected Features: [False False  True  True False False  True False False False False False\n",
      " False False False False False False]\n",
      "Feature Ranking: [ 7 13  1  1  3  2  1  9  4 16 12  5 15 14  6  8 10 11]\n"
     ]
    }
   ],
   "source": [
    "#this algorithm takes a little more time (~5min)... so don't get impatient\n",
    "out = 2\n",
    "train = deepcopy(train_all)\n",
    "train = train[train['speaker']!=out]\n",
    "#transform data\n",
    "y, X = dmatrices(features, train, return_type=\"dataframe\")\n",
    "y = np.ravel(y)\n",
    "# feature extraction\n",
    "number_of_Features = 3\n",
    "model = LogisticRegression()\n",
    "rfe = RFE(model, number_of_Features)\n",
    "fit = rfe.fit(X, y)\n",
    "\n",
    "print(\"Num Features: %d\") % fit.n_features_\n",
    "print(\"Selected Features: %s\") % fit.support_\n",
    "print(\"Feature Ranking: %s\") % fit.ranking_\n",
    "\n",
    "#name_dict = {str(i+1):names[i] for i in range(len(names))}\n",
    "#name_dict['0'] = 'NAN'\n",
    "#results = sorted([(list(fit.scores_)[i],name_dict[str(i)]) for i in range(len(list(fit.scores_)))])\n",
    "#results = list(reversed(results)) \n",
    "#print \"\\n\".join([str(tupel[0])+\"\\t\"+tupel[1] for tupel in results])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label ~ time_in_sec +pcm_RMSenergy_sma + rms_minus_one + rms_minus_two + rms_minus_three + rms_minus_four +pcm_LOGenergy_sma + pcm_loudness_sma + pcm_intensity_sma  +zscore + duration + intensity_mean + intensity_slope + voicingFinalUnclipped_sma + voicingFinalUnclipped_slope +  wml + wml_trigram\n"
     ]
    }
   ],
   "source": [
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "17\n",
      "1\tpcm_RMSenergy_sma\n",
      "1\trms_minus_four\n",
      "1\trms_minus_one\n",
      "2\trms_minus_three\n",
      "3\trms_minus_two\n",
      "4\tpcm_loudness_sma\n",
      "5\tduration\n",
      "6\tvoicingFinalUnclipped_sma\n",
      "7\tlabel\n",
      "8\tvoicingFinalUnclipped_slope\n",
      "9\tpcm_LOGenergy_sma\n",
      "10\twml\n",
      "11\twml_trigram\n",
      "12\tzscore\n",
      "13\ttime_in_sec\n",
      "14\tintensity_slope\n",
      "15\tintensity_mean\n",
      "16\tpcm_intensity_sma\n"
     ]
    }
   ],
   "source": [
    "name_dict = {str(i+1):names[i] for i in range(len(names))}\n",
    "name_dict['0'] = 'label'\n",
    "frank = '7 13  1  1  3  2  1  9  4 16 12  5 15 14  6  8 10 11'.split(' ')\n",
    "frank = [f for f in frank if f != \"\"]\n",
    "print len(frank)\n",
    "print len(names)\n",
    "tupel_rank = [(int(frank[i]), name_dict[str(i)]) for i in range(len(frank))]\n",
    "tupel_rank = sorted(tupel_rank)\n",
    "#if feat != '':\n",
    "    #    print name_dict[feat.strip()]\n",
    "print \"\\n\".join([str(t[0])+'\\t'+t[1] for t in tupel_rank])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "#Don't know how useful the following is\n",
    "#it's really really slow -> i let it run an hour and there was no output\n",
    "#it's another option to get the n best features\n",
    "###########################\n",
    "#from sklearn.svm import SVR\n",
    "#n_features = 5\n",
    "#estimator = SVR(kernel=\"linear\")\n",
    "#selector = RFE(estimator, n_features, step=1)\n",
    "#selector = selector.fit(X, y)\n",
    "#print selector.support_ \n",
    "#print selector.ranking_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
